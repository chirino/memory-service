---
layout: ../../layouts/DocsLayout.astro
title: Configuration
description: Configure Memory Service databases, vector stores, and authentication using environment variables or application properties.
---

import ConfigToggle from '../../components/ConfigToggle.astro';
import Cfg from '../../components/Cfg.astro';
import ConfigBlock from '../../components/ConfigBlock.astro';

Memory Service is configured through environment variables or application properties. Use the toggle below to switch between formats.

<ConfigToggle />

> **Tip:** Your format preference is saved across visits. Environment variables follow Quarkus conventions: dots and hyphens become underscores, all uppercase.

## Server Configuration

These are the core server configuration options:

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.datastore.type" /> | `postgres`, `mongo`, `mongodb` | `postgres` | Database backend for storing conversations |
| <Cfg p="memory-service.datastore.migrate-at-start" /> | `true`, `false` | `true` | Run database migrations at startup (routed to the correct backend automatically) |
| <Cfg p="memory-service.cache.type" /> | `none`, `redis`, `infinispan` | `none` | Cache backend for distributed caching (used by response resumer and future cache features) |
| <Cfg p="memory-service.vector.type" /> | `none`, `pgvector`, `postgres`, `mongo`, `mongodb` | `none` | Vector store for semantic search |
| <Cfg p="memory-service.temp-dir" /> | path | system temp dir | Directory for temporary files (attachment downloads, response resumer, etc.) |

## Database Configuration

Memory Service supports multiple database backends for storing conversation data. When you set <Cfg p="memory-service.datastore.type" />, the service automatically routes database migrations to the correct Liquibase backend. Selecting `mongo` requires a few additional settings to keep the unused PostgreSQL/Hibernate ORM subsystem inactive (see the MongoDB section below).

### PostgreSQL (Recommended)

<ConfigBlock property={`# Select PostgreSQL as the datastore
memory-service.datastore.type=postgres

# PostgreSQL connection
quarkus.datasource.db-kind=postgresql
quarkus.datasource.jdbc.url=jdbc:postgresql://localhost:5432/memoryservice
quarkus.datasource.username=postgres
quarkus.datasource.password=postgres`} />

### MongoDB

<ConfigBlock property={`# Select MongoDB as the datastore
memory-service.datastore.type=mongo

# MongoDB connection
quarkus.mongodb.connection-string=mongodb://localhost:27017
quarkus.mongodb.database=memoryservice
quarkus.mongodb.credentials.auth-source=admin`} />

In production, MongoDB deployments also require settings to keep the unused PostgreSQL/Hibernate ORM subsystem inactive. The `DatastoreConfigSourceFactory` handles MongoDB Liquibase routing automatically, but the JDBC datasource and PostgreSQL Liquibase settings use Quarkus `BUILD_AND_RUN_TIME_FIXED` config properties that must be set via environment variables:

<ConfigBlock property={`# Dummy JDBC URL keeps Hibernate ORM active (no actual connection is made)
quarkus.datasource.jdbc.url=jdbc:postgresql://unused:5432/unused
quarkus.datasource.jdbc.initial-size=0
quarkus.datasource.jdbc.min-size=0
quarkus.datasource.jdbc.max-size=1

# Disable PostgreSQL Liquibase (migrations route to MongoDB automatically)
quarkus.liquibase.migrate-at-start=false
quarkus.liquibase.validate-on-migrate=false`} />

> **Note:** These settings are pre-configured in the [kustomize MongoDB component](/docs/deployment/kubernetes/) and the Docker Compose MongoDB example below. You only need to set them manually for custom deployments.

## Cache Configuration

Memory Service uses a unified cache configuration for all cache-dependent features, including the response resumer and memory entries cache. Configure the cache backend once, and all features will use it automatically.

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.cache.type" /> | `none`, `redis`, `infinispan` | `none` | Cache backend for distributed caching |
| <Cfg p="memory-service.redis.hosts" /> | Redis URL | `redis://localhost:6379` | Redis connection URL |
| <Cfg p="memory-service.cache.redis.client" /> | client name | default | Optional: specify a named Redis client |
| <Cfg p="memory-service.cache.infinispan.startup-timeout" /> | duration | `PT30S` | Startup timeout for Infinispan connection |
| <Cfg p="memory-service.cache.infinispan.memory-entries-cache-name" /> | string | `memory-entries` | Infinispan cache name for memory entries |
| <Cfg p="memory-service.cache.infinispan.response-recordings-cache-name" /> | string | `response-recordings` | Infinispan cache name for response recordings |

### Memory Entries Cache

When a cache backend is configured, Memory Service caches memory entries to reduce database load and improve GET/sync latency. The cache stores the complete list of memory entries at the latest epoch for each conversation/client pair.

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.cache.epoch.ttl" /> | duration | `PT10M` | TTL for cached memory entries (sliding window - refreshed on access) |

Features of the memory entries cache:

- **Automatic population**: Cache is populated on first read and updated after sync operations
- **Sliding TTL**: TTL is refreshed on every cache access (get or set)
- **In-memory pagination**: Cache stores complete entry list; pagination is applied in-memory
- **Graceful degradation**: Falls back to database queries if cache is unavailable

### Response Resumer Settings

The Response Resumer enables clients to reconnect to in-progress streaming responses after a network interruption. It automatically uses the configured cache backend.

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.response-resumer.enabled" /> | `true`, `false` | auto-detect | Enable/disable response resumer (auto-enabled when cache.type is redis or infinispan) |
| <Cfg p="memory-service.response-resumer.temp-file-retention" /> | duration | `PT30M` | How long to retain temp files |
| <Cfg p="memory-service.grpc-advertised-address" /> | `host:port` | auto-detected | Address clients use to reconnect (for multi-instance deployments) |

### Redis Backend

<ConfigBlock property={`# Enable Redis cache (response resumer will automatically use it)
memory-service.cache.type=redis

# Redis connection
memory-service.redis.hosts=redis://localhost:6379

# Optional: specify a named Redis client
memory-service.cache.redis.client=my-redis-client

# Optional: disable response resumer even with cache enabled
memory-service.response-resumer.enabled=false`} />

### Infinispan Backend

<ConfigBlock property={`# Enable Infinispan cache (response resumer will automatically use it)
memory-service.cache.type=infinispan

# Infinispan connection
quarkus.infinispan-client.hosts=localhost:11222
quarkus.infinispan-client.username=admin
quarkus.infinispan-client.password=password

# Optional: startup timeout for Infinispan connection
memory-service.cache.infinispan.startup-timeout=PT30S

# Optional: custom cache names (useful for multi-tenant or multi-environment clusters)
# memory-service.cache.infinispan.memory-entries-cache-name=my-memory-entries
# memory-service.cache.infinispan.response-recordings-cache-name=my-response-recordings

# Optional: disable response resumer even with cache enabled
memory-service.response-resumer.enabled=false`} />

## Attachment Storage

Configure file attachment storage, size limits, and lifecycle.

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.attachments.store" /> | `db`, `s3` | `db` | Storage backend for uploaded files |
| <Cfg p="memory-service.attachments.max-size" /> | memory size | `10M` | Maximum file size per upload (e.g., `10M`, `512K`, `1G`). The HTTP body size limit is auto-derived as 2x this value. |
| <Cfg p="memory-service.attachments.default-expires-in" /> | duration | `PT1H` | Default TTL for unlinked attachments |
| <Cfg p="memory-service.attachments.max-expires-in" /> | duration | `PT24H` | Maximum allowed TTL clients can request |
| <Cfg p="memory-service.attachments.cleanup-interval" /> | duration | `PT5M` | How often the cleanup job runs to delete expired unlinked attachments |
| <Cfg p="memory-service.attachments.download-url-expires-in" /> | duration | `PT5M` | Signed download URL expiry |

### S3 Storage

When using S3 as the attachment storage backend:

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.attachments.s3.bucket" /> | string | `memory-service-attachments` | S3 bucket name |
| <Cfg p="memory-service.attachments.s3.prefix" /> | string | _(empty)_ | Optional key prefix for all objects |
| <Cfg p="memory-service.attachments.s3.direct-download" /> | `true`, `false` | `true` | When `true`, download URLs redirect clients directly to S3 via presigned URLs. When `false`, downloads are proxied through memory-service. |
| <Cfg p="memory-service.attachments.s3.external-endpoint" /> | URL | _(none)_ | Override the endpoint used in presigned URLs. Only relevant when `direct-download` is `true`. Use this when the internal S3 endpoint (e.g., `http://minio:9000`) is not reachable from clients. |

<ConfigBlock property={`# Select S3 storage
memory-service.attachments.store=s3

# S3 bucket configuration
memory-service.attachments.s3.bucket=memory-service-attachments`} />

**Direct download vs. proxy mode:** By default, the `/v1/attachments/{id}` and `/v1/attachments/{id}/download-url` endpoints return presigned S3 URLs that redirect clients directly to the S3 backend. This offloads bandwidth from memory-service but requires S3 to be reachable from the client. Set <Cfg p="memory-service.attachments.s3.direct-download" /> to `false` to proxy downloads through memory-service instead.

When using a self-hosted S3-compatible store (like MinIO) that is only reachable at an internal address, you have two options:

1. **Proxy mode** — set <Cfg p="memory-service.attachments.s3.direct-download" /> to `false`. Downloads stream through memory-service; no client-reachable S3 endpoint needed.
2. **Direct download with external endpoint** — keep `direct-download` as `true` and set <Cfg p="memory-service.attachments.s3.external-endpoint" /> to a client-reachable URL (e.g., `http://minio-api.example.com`). Presigned URLs will use this endpoint instead of the internal one.

See [Attachments](/docs/concepts/attachments/) for details on how attachments work.

## Vector Store Configuration

For semantic search capabilities, configure a vector store and embedding settings.

### Embedding Configuration

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory.embedding.type" /> | `none`, `hash` | `hash` | Embedding algorithm (`hash` is a simple built-in implementation) |
| <Cfg p="memory.embedding.dimension" /> | integer | `256` | Vector dimension size |

### pgvector (PostgreSQL)

When using PostgreSQL with the pgvector extension:

<ConfigBlock property={`# Enable pgvector for semantic search
memory-service.vector.type=pgvector

# Embedding configuration
memory.embedding.type=hash
memory.embedding.dimension=256`} />

### MongoDB Atlas Vector Search

<ConfigBlock property={`# Enable MongoDB vector search
memory-service.vector.type=mongodb

# Embedding configuration
memory.embedding.type=hash
memory.embedding.dimension=256`} />

## API Key Authentication

Memory Service supports API key authentication for trusted agents. Configure API keys by client ID:

<ConfigBlock
  property={`# Format: memory-service.api-keys.<client-id>=key1,key2,...
memory-service.api-keys.agent-a=agent-a-key-1,agent-a-key-2
memory-service.api-keys.agent-b=agent-b-key-1`}
  env={`# Format: MEMORY_SERVICE_API_KEYS_<CLIENT_ID>=key1,key2,...
MEMORY_SERVICE_API_KEYS_AGENT_A=agent-a-key-1,agent-a-key-2
MEMORY_SERVICE_API_KEYS_AGENT_B=agent-b-key-1`}
/>

Clients include the API key in requests via the `X-API-Key` header.

## OIDC Authentication

Memory Service supports OIDC authentication via Keycloak or any compliant provider.

<ConfigBlock property={`# OIDC configuration
quarkus.oidc.auth-server-url=http://localhost:8180/realms/memory-service
quarkus.oidc.client-id=memory-service
quarkus.oidc.credentials.secret=your-client-secret`} />

## Admin Access Configuration

Memory Service provides `/v1/admin/*` APIs for platform administrators and auditors.
Access is controlled through role assignment, which can be configured via OIDC token roles,
explicit user lists, or API key client IDs. All three mechanisms are checked — if any
grants a role, the caller has that role.

### Roles

| Role | Access | Description |
|------|--------|-------------|
| `admin` | Read + Write | Full administrative access across all users. Implies `auditor` and `indexer`. |
| `auditor` | Read-only | View any user's conversations and search system-wide. Cannot modify data. |
| `indexer` | Index only | Index any conversation's transcript for search. Cannot view or modify other data. |

### Role Assignment

Roles can be assigned through three complementary mechanisms:

#### OIDC Role Mapping

Map OIDC token roles to internal Memory Service roles. This is useful when the OIDC
provider uses different role names (e.g., `administrator` instead of `admin`).

| Property | Default | Description |
|----------|---------|-------------|
| <Cfg p="memory-service.roles.admin.oidc.role" /> | _(none)_ | OIDC role name that maps to the internal `admin` role |
| <Cfg p="memory-service.roles.auditor.oidc.role" /> | _(none)_ | OIDC role name that maps to the internal `auditor` role |
| <Cfg p="memory-service.roles.indexer.oidc.role" /> | _(none)_ | OIDC role name that maps to the internal `indexer` role |

<ConfigBlock property={`# Map OIDC "administrator" role to internal "admin" role
memory-service.roles.admin.oidc.role=administrator

# Map OIDC "manager" role to internal "auditor" role
memory-service.roles.auditor.oidc.role=manager

# Map OIDC "transcript-indexer" role to internal "indexer" role
memory-service.roles.indexer.oidc.role=transcript-indexer`} />

#### User-Based Assignment

Assign roles directly to user IDs (matched against the OIDC token principal name):

| Property | Default | Description |
|----------|---------|-------------|
| <Cfg p="memory-service.roles.admin.users" /> | _(empty)_ | Comma-separated list of user IDs with admin access |
| <Cfg p="memory-service.roles.auditor.users" /> | _(empty)_ | Comma-separated list of user IDs with auditor access |
| <Cfg p="memory-service.roles.indexer.users" /> | _(empty)_ | Comma-separated list of user IDs with indexer access |

<ConfigBlock property={`memory-service.roles.admin.users=alice,bob
memory-service.roles.auditor.users=charlie,dave
memory-service.roles.indexer.users=indexer-user`} />

#### Client-Based Assignment (API Key)

Assign roles to API key client IDs, allowing agents or services to call admin APIs.
The client ID is resolved from the `X-API-Key` header via the existing API key configuration.

| Property | Default | Description |
|----------|---------|-------------|
| <Cfg p="memory-service.roles.admin.clients" /> | _(empty)_ | Comma-separated list of API key client IDs with admin access |
| <Cfg p="memory-service.roles.auditor.clients" /> | _(empty)_ | Comma-separated list of API key client IDs with auditor access |
| <Cfg p="memory-service.roles.indexer.clients" /> | _(empty)_ | Comma-separated list of API key client IDs with indexer access |

<ConfigBlock property={`memory-service.roles.admin.clients=admin-agent
memory-service.roles.auditor.clients=monitoring-agent,audit-agent
memory-service.roles.indexer.clients=indexer-service,summarizer-agent`} />

### Audit Logging

All admin API calls are logged to a dedicated logger (`io.github.chirino.memory.admin.audit`).
Each request can include a `justification` field explaining why the admin action was taken.

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.admin.require-justification" /> | `true`, `false` | `false` | When `true`, all admin API calls must include a `justification` or receive `400 Bad Request` |

<ConfigBlock property={`# Require justification for all admin operations
memory-service.admin.require-justification=true`} />

To route admin audit logs to a separate file or external system, configure the Quarkus
logging category:

<ConfigBlock property={`# Set admin audit log level
quarkus.log.category."io.github.chirino.memory.admin.audit".level=INFO`} />

## Server Configuration

<ConfigBlock property={`# HTTP port (default: 8080)
quarkus.http.port=8080

# gRPC port (uses HTTP port when use-separate-server=false)
quarkus.grpc.server.use-separate-server=false

# Enable CORS
memory-service.cors.enabled=true
memory-service.cors.origins=http://localhost:3000`} />

## Production Recommendations

For production deployments, consider the following environment variables:

### Connection Pooling

<ConfigBlock property={`# Database connection pool
quarkus.datasource.jdbc.max-size=20
quarkus.datasource.jdbc.min-size=5`} />

### Health Checks

<ConfigBlock property={`# Enable health endpoints
quarkus.health.extensions.enabled=true`} />

### Logging

<ConfigBlock property={`# Set log level
quarkus.log.level=INFO
quarkus.log.category."io.github.chirino".level=DEBUG`} />

## Monitoring

Memory Service exposes Prometheus metrics and provides admin stats endpoints that query Prometheus for aggregated metrics across all service replicas.

### Metrics Endpoint

Memory Service exposes metrics in Prometheus format at `/q/metrics`:

<ConfigBlock property={`# Enable Prometheus metrics endpoint (enabled by default)
quarkus.micrometer.export.prometheus.enabled=true

# Metrics endpoint path (default: /q/metrics)
quarkus.micrometer.export.prometheus.path=/q/metrics`} />

### Application Tag

All Memory Service metrics include an `application="memory-service"` tag. This tag helps:

- **Filter metrics** when multiple services are scraped by the same Prometheus
- **Build dashboards** that only show memory-service data
- **Configure alerts** specific to memory-service

Example PromQL queries using the application tag:

```promql
# Request rate for memory-service only
sum(rate(http_server_requests_seconds_count{application="memory-service"}[5m]))

# Store operation latency (P95) for memory-service
histogram_quantile(0.95, sum(rate(memory_store_operation_seconds_bucket{application="memory-service"}[5m])) by (le, operation))
```

### Prometheus Scrape Configuration

Configure Prometheus to scrape metrics from all Memory Service replicas:

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'memory-service'
    scrape_interval: 15s
    metrics_path: /q/metrics
    static_configs:
      - targets: ['memory-service:8080']
    # For Kubernetes, use service discovery instead:
    # kubernetes_sd_configs:
    #   - role: pod
    #     selectors:
    #       - role: pod
    #         label: "app=memory-service"
```

To keep only Memory Service metrics (useful when scraping multiple services):

```yaml
scrape_configs:
  - job_name: 'memory-service'
    scrape_interval: 15s
    metrics_path: /q/metrics
    static_configs:
      - targets: ['memory-service:8080']
    # Keep only metrics with application="memory-service" tag
    metric_relabel_configs:
      - source_labels: [application]
        regex: memory-service
        action: keep
```

### Admin Stats Endpoints

Memory Service provides `/v1/admin/stats/*` endpoints that query Prometheus for pre-aggregated metrics. These endpoints require the Prometheus URL to be configured:

| Property | Values | Default | Description |
|----------|--------|---------|-------------|
| <Cfg p="memory-service.prometheus.url" /> | URL | _(none)_ | Prometheus server URL for admin stats queries |

<ConfigBlock property={`# Configure Prometheus URL for admin stats endpoints
memory-service.prometheus.url=http://prometheus:9090`} />

When <Cfg p="memory-service.prometheus.url" /> is not configured, admin stats endpoints return **501 Not Implemented**. All other Memory Service functionality works normally.

#### Available Stats Endpoints

| Endpoint | Description | Required Metrics |
|----------|-------------|------------------|
| `/v1/admin/stats/request-rate` | HTTP request rate (requests/sec) | `http_server_requests_seconds_count` |
| `/v1/admin/stats/error-rate` | 5xx error rate (percent) | `http_server_requests_seconds_count` |
| `/v1/admin/stats/latency-p95` | P95 response latency (seconds) | `http_server_requests_seconds_bucket` |
| `/v1/admin/stats/cache-hit-rate` | Cache hit rate (percent) | `memory_entries_cache_hits_total`, `memory_entries_cache_misses_total` |
| `/v1/admin/stats/db-pool-utilization` | DB connection pool usage (percent) | `agroal_active_count`, `agroal_available_count` |
| `/v1/admin/stats/store-latency-p95` | Store operation P95 latency by type | `memory_store_operation_seconds_bucket` |
| `/v1/admin/stats/store-throughput` | Store operations/sec by type | `memory_store_operation_seconds_count` |

### Required Metrics

For all admin stats endpoints to function correctly, Prometheus must scrape the following metrics from Memory Service:

#### HTTP Metrics (Automatic)

These are automatically provided by Quarkus Micrometer:

| Metric | Type | Description |
|--------|------|-------------|
| `http_server_requests_seconds_count` | Counter | Total HTTP requests by method, uri, status |
| `http_server_requests_seconds_sum` | Counter | Total request duration |
| `http_server_requests_seconds_bucket` | Histogram | Request duration distribution |

#### Cache Metrics (When Cache Enabled)

Available when <Cfg p="memory-service.cache.type" /> is `redis` or `infinispan`:

| Metric | Type | Description |
|--------|------|-------------|
| `memory_entries_cache_hits_total` | Counter | Cache hits for memory entries |
| `memory_entries_cache_misses_total` | Counter | Cache misses for memory entries |
| `memory_entries_cache_errors_total` | Counter | Cache errors for memory entries |

#### Database Pool Metrics (Automatic)

Automatically provided by Quarkus/Agroal for PostgreSQL:

| Metric | Type | Description |
|--------|------|-------------|
| `agroal_active_count` | Gauge | Active database connections |
| `agroal_available_count` | Gauge | Available database connections |
| `agroal_awaiting_count` | Gauge | Requests waiting for a connection |

#### Store Operation Metrics (Automatic)

Automatically provided by MeteredMemoryStore:

| Metric | Type | Description |
|--------|------|-------------|
| `memory_store_operation_seconds_count` | Counter | Store operations by operation type |
| `memory_store_operation_seconds_sum` | Counter | Total operation duration by type |
| `memory_store_operation_seconds_bucket` | Histogram | Operation duration distribution by type |

The `operation` label identifies the operation type (e.g., `createConversation`, `appendAgentEntries`, `getEntries`).

### Example: Full Monitoring Stack

```yaml
# docker-compose.yml
services:
  memory-service:
    image: ghcr.io/chirino/memory-service:latest
    environment:
      MEMORY_SERVICE_DATASTORE_TYPE: postgres
      QUARKUS_DATASOURCE_JDBC_URL: jdbc:postgresql://postgres:5432/memoryservice
      QUARKUS_DATASOURCE_USERNAME: postgres
      QUARKUS_DATASOURCE_PASSWORD: postgres
      # Enable admin stats to query Prometheus
      MEMORY_SERVICE_PROMETHEUS_URL: http://prometheus:9090
    ports:
      - "8080:8080"

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3000:3000"
```

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'memory-service'
    static_configs:
      - targets: ['memory-service:8080']
    metrics_path: /q/metrics
```

## Example: Docker Compose

```yaml
services:
  memory-service:
    image: ghcr.io/chirino/memory-service:latest
    environment:
      # Datastore selection
      MEMORY_SERVICE_DATASTORE_TYPE: postgres

      # PostgreSQL connection
      QUARKUS_DATASOURCE_DB_KIND: postgresql
      QUARKUS_DATASOURCE_JDBC_URL: jdbc:postgresql://postgres:5432/memoryservice
      QUARKUS_DATASOURCE_USERNAME: postgres
      QUARKUS_DATASOURCE_PASSWORD: postgres

      # Cache with Redis (response resumer and memory entries cache automatically enabled)
      MEMORY_SERVICE_CACHE_TYPE: redis
      MEMORY_SERVICE_REDIS_HOSTS: redis://redis:6379
      # Optional: memory entries cache TTL (default: 10 minutes)
      # MEMORY_SERVICE_CACHE_EPOCH_TTL: PT10M

      # Authentication
      QUARKUS_OIDC_AUTH_SERVER_URL: http://keycloak:8180/realms/memory-service
      QUARKUS_OIDC_CLIENT_ID: memory-service
      QUARKUS_OIDC_CREDENTIALS_SECRET: ${OIDC_SECRET}
    depends_on:
      - postgres
      - redis
```

## Next Steps

- Learn about [Core Concepts](/docs/concepts/conversations/)
- Explore [Deployment Options](/docs/deployment/docker/)
