---
layout: ../../../layouts/DocsLayout.astro
title: Response Resumption
description: Streaming responses, response resumption, and cancellation.
---
import CodeFromFile from '../../../components/CodeFromFile.astro';
import TestScenario from '../../../components/TestScenario.astro';
import CurlTest from '../../../components/CurlTest.astro';

This guide covers streaming responses, response resumption, and cancellation — so users can reconnect after a disconnect and pick up where they left off. For a conceptual overview of how response resumption works, including the gRPC service contract and multi-instance redirect behavior, see [Response Resumption Concepts](/docs/concepts/response-resumption/).

## Prerequisites

**Starting checkpoint**: This guide starts from [quarkus/examples/doc-checkpoints/03-with-history](https://github.com/chirino/memory-service/tree/main/quarkus/examples/doc-checkpoints/03-with-history)

Make sure you've completed the previous guides:
- [Getting Started](/docs/quarkus/getting-started/) - Basic memory service integration
- [Conversation History](/docs/quarkus/conversation-history/) - History recording and APIs

## Streaming Responses

When users disconnect during a streaming response (page reload, network issues), you can resume the streaming response from where they left off. This requires that the agent uses streaming responses. Let's update the agent to use streaming responses with `Multi<String>` return types instead of `String`.

Update the `Agent.java` to use streaming responses:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/05-response-resumption/src/main/java/org/acme/Agent.java"
  lang="java"
/>

**What changed**: The `chat` method return type changed from `String` to `Multi<String>`. **Why**: `Multi<String>` is Mutiny's reactive stream type and tells LangChain4j to emit each token as it arrives from the LLM rather than waiting for the complete response. This is a prerequisite for streaming to clients and for response resumption — the Memory Service can only replay a stream if it was produced as a stream in the first place.

Update the `HistoryRecordingAgent.java` to use streaming responses:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/05-response-resumption/src/main/java/org/acme/HistoryRecordingAgent.java"
  lang="java"
/>

**What changed**: The wrapper's `chat` method return type was updated from `String` to `Multi<String>` to match the agent. **Why**: The `@RecordConversation` interceptor needs to observe the full token stream to record the complete response only after it finishes. By passing through `Multi<String>`, the interceptor can transparently tap into the stream, accumulate tokens, and write the final entry to the history channel once the stream completes.

Update `ChatResource.java` to use Server Sent Events (SSE) to stream the responses to the client:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/05-response-resumption/src/main/java/org/acme/ChatResource.java"
  lang="java"
/>

**What changed**: The `chat` method now returns `Multi<String>` instead of `String`. **Why**: Returning a reactive stream from a JAX-RS endpoint causes Quarkus RESTEasy Reactive to automatically stream each emitted token to the HTTP client as a Server-Sent Event. The client receives tokens incrementally as the LLM produces them, instead of waiting for the full response.

<TestScenario checkpoint="quarkus/examples/doc-checkpoints/05-response-resumption">

Test it with curl:

<CurlTest steps={`
Then the response status should be 200
And the response should match pattern "\\w+"
`}>

```bash
curl -NsSfX POST http://localhost:9090/chat/bafd53b0-ee0d-4d5f-83e3-406fbc3506cb \
  -H "Content-Type: text/plain" \
  -H "Authorization: Bearer $(get-token)" \
  -d "Write a 4 paragraph story about a cat."
```

</CurlTest>

</TestScenario>

You should see the response streaming to your command line.

Now browse to the demo agent app at [http://localhost:8080/?conversationId=bafd53b0-ee0d-4d5f-83e3-406fbc3506cb](http://localhost:8080/?conversationId=bafd53b0-ee0d-4d5f-83e3-406fbc3506cb)
and you should see the response streaming to the browser.


## Response Resumption

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/05-response-resumption/src/main/java/org/acme/ResumeResource.java"
  lang="java"
/>

**What changed**: Created `ResumeResource` with three endpoints: `POST /resume-check` to check whether a response is in progress for a list of conversation IDs, `GET /{conversationId}/resume` to replay the in-progress stream via SSE, and `POST /{conversationId}/cancel` to abort a running response. **Why**: When a user disconnects mid-stream (page reload, network drop), the LLM is still generating tokens on the server. The `ResponseResumer` lets the client reconnect and receive the remainder of the response without resubmitting the message, and `cancelResponse` lets users abort a generation that is taking too long.

Test it with curl:

```bash
curl -NsSfX POST http://localhost:9090/chat/bafd53b0-ee0d-4d5f-83e3-406fbc3506cb \
  -H "Content-Type: text/plain" \
  -H "Authorization: Bearer $(get-token)" \
  -d "Write a 4 paragraph story about a cat."
```

And while the response is streaming, you can check use the following to check to see if the conversation has responses in progress:

```bash
curl -sSfX POST http://localhost:9090/v1/conversations/resume-check \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $(get-token)" \
  -d '["bafd53b0-ee0d-4d5f-83e3-406fbc3506cb"]' | jq
```

And to resume a conversation, you can run the following command in a new terminal:

```bash
curl -NsSfX GET http://localhost:9090/v1/conversations/bafd53b0-ee0d-4d5f-83e3-406fbc3506cb/resume \
  -H "Authorization: Bearer $(get-token)"
```

You should see the response streaming to your command line.

## Canceling a Response

To cancel a response, you can run the following command:

```bash
curl -sSfX POST http://localhost:9090/v1/conversations/bafd53b0-ee0d-4d5f-83e3-406fbc3506cb/cancel \
  -H "Authorization: Bearer $(get-token)"
```

You should see the response get canceled.

## Next Steps

- [Conversation Sharing](/docs/quarkus/sharing/) - Share conversations with other users.
- [Dev Services](/docs/quarkus/dev-services/) - Automatic memory-service container startup for development and testing.
