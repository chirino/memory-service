---
layout: ../../../layouts/DocsLayout.astro
title: Quarkus Getting Started
description: Step-by-step guide to integrating Memory Service with your Quarkus AI agent.
---
import { Code } from 'astro:components';
import { PROJECT_VERSION } from '../../../config';
import CodeFromFile from '../../../components/CodeFromFile.astro';
import TestScenario from '../../../components/TestScenario.astro';
import CurlTest from '../../../components/CurlTest.astro';


This guide walks you through integrating Memory Service with a Quarkus AI agent. You'll start with basic chat memory and can progressively add features in the follow-up guides.

Make sure you've completed the [prerequisites](/docs/quarkus/) before starting this guide.

## Step 1: Create a Simple LangChain4j App

**Starting checkpoint**: View the complete code at [quarkus/examples/doc-checkpoints/01-basic-agent](https://github.com/chirino/memory-service/tree/main/quarkus/examples/doc-checkpoints/01-basic-agent)

First, let's create a new [Quarkus](https://quarkus.io/get-started/) application with: 

```plain
quarkus create example
cd example
```

Add the LangChain4j OpenAI dependency to your `pom.xml`:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/01-basic-agent/pom.xml"
  lang="xml"
  before={2}
  after={2}
>quarkus-langchain4j-openai</CodeFromFile>

**Why**: This extension integrates LangChain4j with Quarkus and provides built-in support for calling OpenAI-compatible LLMs, along with CDI-managed AI service beans via `@RegisterAiService`.

Create a simple AI service interface:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/01-basic-agent/src/main/java/org/acme/Agent.java"
  lang="java"
/>

**Why**: LangChain4j generates the LLM-calling implementation at compile time from the interface signature. Declaring it as an interface means you never write networking code — Quarkus injects a fully configured AI service bean wherever you use `@Inject Agent`.

Create a REST resource to expose the agent:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/01-basic-agent/src/main/java/org/acme/ChatResource.java"
  lang="java"
/>

**Why**: This is the entry point that HTTP clients hit. The resource delegates immediately to the AI service, keeping the REST layer thin and the LLM interaction logic in the `Agent` interface.

Configure your LLM in `application.properties` so it gets OpenAI credentials from the environment variables and change the HTTP port to 9090 to avoid conflict with services that will be started later:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/01-basic-agent/src/main/resources/application.properties"
  lang="properties"
/>

**Why**: Reading credentials from environment variables keeps secrets out of source control. The port is moved to 9090 so it doesn't conflict with the Memory Service and Keycloak that will be started on ports 8082 and 8081 in later steps.

<TestScenario checkpoint="quarkus/examples/doc-checkpoints/01-basic-agent">

Run your agent:

```bash
export OPENAI_API_KEY=your-api-key
```
```bash
./mvnw quarkus:dev
```

Test it with curl:

<CurlTest steps={`
Then the response status should be 200
And the response body should be text:
"""
I am Claude, an AI assistant created by Anthropic. I'm here to help answer questions and have conversations on a wide variety of topics. How can I assist you today?
"""
`}>

```bash
curl -NsSfX POST http://localhost:9090/chat \
  -H "Content-Type: text/plain" \
  -d "Hi, I'm Hiram, who are you?"
```

</CurlTest>

**Expected**: The agent responds but has no memory of your name.

<CurlTest steps={`
Then the response status should be 200
And the response should not contain "Hiram"
`}>

```bash
curl -NsSfX POST http://localhost:9090/chat \
  -H "Content-Type: text/plain" \
  -d "Who am I?"
```

</CurlTest>

</TestScenario>

Let's add conversation memory.

## Step 2: Add Memory Service Extension

**Starting checkpoint**: View the complete code at [quarkus/examples/doc-checkpoints/02-with-memory](https://github.com/chirino/memory-service/tree/main/quarkus/examples/doc-checkpoints/02-with-memory)

Add the Memory Service extension to your `pom.xml`:

<Code lang="xml" code={`<dependency>
    <groupId>io.github.chirino.memory-service</groupId>
    <artifactId>memory-service-extension</artifactId>
    <version>${PROJECT_VERSION}</version>
</dependency>
`} />

Update the Agent interface to accept a conversation ID using the `@MemoryId` annotation:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/02-with-memory/src/main/java/org/acme/Agent.java"
  lang="java"
/>

**Why**: The `@MemoryId` annotation tells LangChain4j which conversation the call belongs to. The Memory Service extension uses this ID to load and save the agent's memory so each conversation is isolated and the LLM receives only the history for that specific conversation.

Update the REST resource to accept a conversation ID:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/02-with-memory/src/main/java/org/acme/ChatResource.java"
  lang="java"
/>

**What changed**: The endpoint path now includes `/{conversationId}` and the method accepts it as a `@PathParam`. The `@Blocking` annotation was also added. **Why**: Passing the conversation ID in the URL makes each conversation addressable by the caller. `@Blocking` is required here because the Memory Service client makes synchronous HTTP calls to store and retrieve memory, which would deadlock on Vert.x's non-blocking event loop.

Start the Memory Service in Docker Compose following the [Getting Started](/docs/getting-started/) guide.

Configure the agent to connect to the Memory Service and configure OIDC authentication in `application.properties`:

<CodeFromFile
  file="quarkus/examples/doc-checkpoints/02-with-memory/src/main/resources/application.properties"
  lang="properties"
  after={11}
># Memory Service Client</CodeFromFile>

**What changed**: Added Memory Service client URL and API key, OIDC server configuration, and a route policy that requires authentication on `/chat/*`. **Why**: The Memory Service uses a dual-authentication pattern — your Quarkus app authenticates to it using a service account API key, while the user's Bearer token is passed through to enforce ownership of conversations. Enabling OIDC on the Quarkus side allows it to validate and propagate the user's identity automatically.

<TestScenario checkpoint="quarkus/examples/doc-checkpoints/02-with-memory">

Run your agent again:

```bash
export OPENAI_API_KEY=your-api-key
./mvnw quarkus:dev
```

Make sure you define a shell function that can get the bearer token for the bob user:

```bash
function get-token() {
  curl -sSfX POST http://localhost:8081/realms/memory-service/protocol/openid-connect/token \
    -H "Content-Type: application/x-www-form-urlencoded" \
    -d "client_id=memory-service-client" \
    -d "client_secret=change-me" \
    -d "grant_type=password" \
    -d "username=bob" \
    -d "password=bob" \
    | jq -r '.access_token'
}
```


Test it with curl—now with conversation memory:

<CurlTest steps={`
Then the response status should be 200
And the response body should be text:
"""
Hi Hiram! I'm an AI created to help answer questions and provide information. How can I assist you today?
"""
`}>

```bash
curl -NsSfX POST http://localhost:9090/chat/6a6e7762-4569-4f63-b01c-c3666a27428b \
  -H "Content-Type: text/plain" \
  -H "Authorization: Bearer $(get-token)" \
  -d "Hi, I'm Hiram, who are you?"
```

</CurlTest>

**Expected**: The agent now remembers your name from the previous message.

<CurlTest steps={`
Then the response status should be 200
And the response should contain "Hiram"
`}>

```bash
curl -NsSfX POST http://localhost:9090/chat/6a6e7762-4569-4f63-b01c-c3666a27428b \
  -H "Content-Type: text/plain" \
  -H "Authorization: Bearer $(get-token)" \
  -d "Who am I?"
```

</CurlTest>

</TestScenario>

If you browse to the demo agent app at [http://localhost:8080/](http://localhost:8080/), you will see that a conversation has been created with the ID `6a6e7762-4569-4f63-b01c-c3666a27428b`.
But it won't show any messages.  That's because we are not yet storing what we call the history of the conversation.  The only thing being stored is the agent memory, and 
that's not typically what you want to display to a user in a UI.

## Next Steps

Continue to [Conversation History](/docs/quarkus/conversation-history/) to learn how to:
- Record conversation history for frontend display
- Expose conversation APIs (messages, listing)
- Build a complete chat UI experience

Or jump ahead to:
- [Conversation Forking](/docs/quarkus/conversation-forking/) - Branch conversations to explore alternative paths
- [Response Resumption](/docs/quarkus/response-resumption/) - Streaming responses with resume and cancel support

