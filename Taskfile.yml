# yaml-language-server: $schema=https://taskfile.dev/schema.json
# install task from: https://taskfile.dev/docs/installation
version: '3'

vars:
  KIND_CLUSTER_NAME: memory-service
  ENVOY_GATEWAY_VERSION: v1.7.0
  OVERLAY: '{{.OVERLAY | default "postgresql-infinispan"}}'
dotenv:
  - .env
  
tasks:

  site:
    desc: Run the site in dev mode.
    dir: site
    cmds:
      - npm i
      - npm run dev

  image:memory-service:
    desc: Build the memory-service container image
    cmds:
      - docker build -t ghcr.io/chirino/memory-service:latest -f Dockerfile .

  image:chat-quarkus:
    desc: Build the chat-quarkus container image
    cmds:
      - docker build -t ghcr.io/chirino/memory-service-chat-quarkus:latest -f quarkus/examples/chat-quarkus/Dockerfile .

  dev:memory-service:
    desc: Run the memory-service app in dev mode.
    cmds:
      - |
        [ -f .env ] && source .env
        ./mvnw -T 1C install -pl ':memory-service' -am -DskipTests
        ./mvnw -T 1C -pl :memory-service quarkus:dev > memory-service.log

  dev:chat-quarkus:
    desc: Run the chat-quarkus app in dev mode.
    cmds:
      - cd frontends/chat-frontend && npm i
      - ./mvnw -T 1C install -pl ':memory-service-extension-deployment' -am -DskipTests
      - ./mvnw -T 1C -pl :chat-quarkus quarkus:dev -Dquarkus.profile=alt

  secrets:
    desc: Create memory-service secret from current shell environment variables
    cmds:
      - |
        kubectl create secret generic memory-service \
          --namespace memory-service \
          --from-literal=MEMORY_SERVICE_EMBEDDING_OPENAI_API_KEY="${MEMORY_SERVICE_EMBEDDING_OPENAI_API_KEY:-${OPENAI_API_KEY}}" \
          --from-literal=OPENAI_API_KEY="${OPENAI_API_KEY}" \
          --from-literal=OPENAI_BASE_URL="${OPENAI_BASE_URL:-https://api.openai.com}" \
          --dry-run=client -o yaml | kubectl apply -f -

  deploy:
    desc: "Deploy an overlay to the kind cluster (usage: task deploy OVERLAY={{.OVERLAY}})"
    cmds:
      - kubectl apply -k deploy/kustomize/overlays/{{.OVERLAY}}
  undeploy:
    desc: "Remove the deployed overlay (usage: task undeploy OVERLAY={{.OVERLAY}})"
    cmds:
      - kubectl delete -k deploy/kustomize/overlays/{{.OVERLAY}} --ignore-not-found

  kind:deploy:
    desc: "Deploy to kind the overlay (usage: task kind:deploy OVERLAY={{.OVERLAY}})"
    cmds:
      - kubectl apply -k deploy/kustomize/envs/kind/overlays/{{.OVERLAY}}
      - task: secrets
      - kubectl set env deployment/memory-service -n memory-service --from=secret/memory-service

  kind:undeploy:
    desc: "Remove the deployed overlay (usage: task kind:undeploy OVERLAY={{.OVERLAY}})"
    cmds:
      - kubectl delete -k deploy/kustomize/envs/kind/overlays/{{.OVERLAY}} --ignore-not-found

  kind:load:memory-service:
    deps:
      - image:memory-service
    cmds:
      - kind load docker-image ghcr.io/chirino/memory-service:latest --name {{.KIND_CLUSTER_NAME}}
      - kubectl rollout restart deployment/memory-service -n memory-service 2>/dev/null || true

  kind:load:chat-quarkus:
    deps:
      - image:chat-quarkus
    cmds:
      - kind load docker-image ghcr.io/chirino/memory-service-chat-quarkus:latest --name {{.KIND_CLUSTER_NAME}}
      - kubectl rollout restart deployment/chat-quarkus -n memory-service 2>/dev/null || true

  kind:load:
    deps:
      - kind:load:memory-service
      - kind:load:chat-quarkus

  kind:rm:
    desc: Delete the kind cluster
    silent: true
    cmds:
      - kind delete cluster --name {{.KIND_CLUSTER_NAME}} 2>/dev/null || true

  kind:reset:
    desc: Delete and recreate the kind cluster, then deploy
    cmds:
      - task: kind:rm
      - task: kind:init

  kind:init:
    desc: "Deploy to kind: demo + gateway + hostNetwork"
    silent: true
    cmds:
      - |
        if ! kind get clusters 2>/dev/null | grep -q '^{{.KIND_CLUSTER_NAME}}$'; then
          kind create cluster --name {{.KIND_CLUSTER_NAME}} --config deploy/kind-config.yaml
          kubectl cluster-info --context kind-{{.KIND_CLUSTER_NAME}}
        fi
      - |
        if ! kubectl get deployment envoy-gateway -n envoy-gateway-system 2>/dev/null; then
          kubectl apply --server-side --force-conflicts -f https://github.com/envoyproxy/gateway/releases/download/{{.ENVOY_GATEWAY_VERSION}}/install.yaml
          kubectl wait --timeout=5m -n envoy-gateway-system deployment/envoy-gateway --for=condition=Available
          kubectl apply -f deploy/kustomize/components/gateway-envoy/gatewayclass.yaml
        fi
      - kubectl apply -f deploy/kustomize/envs/kind/base/envoyproxy.yaml
      - task: kind:load
      - task: kind:deploy
      - |
        echo ""
        echo "Waiting for all pods to be ready..."
        timeout=300
        elapsed=0
        while [ $elapsed -lt $timeout ]; do
          not_ready=$(kubectl get pods -A --no-headers 2>/dev/null | grep -v 'Running\|Completed\|Succeeded' || true)
          if [ -z "$not_ready" ]; then
            total=$(kubectl get pods -A --no-headers 2>/dev/null | grep -c 'Running' || echo "0")
            echo "All $total pod(s) across all namespaces are running!"
            break
          fi
          echo "--- Pods not yet ready (${elapsed}s elapsed) ---"
          echo "$not_ready"
          echo ""
          sleep 5
          elapsed=$((elapsed + 5))
        done
        if [ $elapsed -ge $timeout ]; then
          echo "WARNING: Timed out waiting for pods after ${timeout}s. Current status:"
          kubectl get pods -A
        fi
      - |
        echo ""
        echo "Overlay: {{.OVERLAY}}"
        echo "Waiting for Gateway to be programmed..."
        kubectl wait -n memory-service gateway/memory-service-gateway --for=condition=Programmed --timeout=2m 2>/dev/null || true
      - task: kind:urls

  kind:urls:
    desc: Show services of the kind cluster
    silent: true
    cmds:
      - |
        echo ""
        echo "Services available at:"
        echo "  Chat:           http://chat.127.0.0.1.nip.io               (bob/bob or alice/alice)"
        echo "  Keycloak:       http://keycloak.127.0.0.1.nip.io           (admin/admin)"
        echo "  Grafana:        http://grafana.127.0.0.1.nip.io/grafana/   (admin/admin)"
        echo "  Prometheus:     http://prometheus.127.0.0.1.nip.io/prometheus/"
        echo "  MinIO Console:  http://minio.127.0.0.1.nip.io              (minioadmin/minioadmin)"
